{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1279e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.cm import ScalarMappable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a846367f-ba9e-499d-a5b7-ca1b9d1f95f3",
   "metadata": {},
   "source": [
    "### This Jupyter notebook is made by Rytis Augustauskas. If you have any questions, please contact rytis.augustauskas@ktu.lt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd734cf7-d0a3-45a6-a154-1f4107461c1f",
   "metadata": {},
   "source": [
    "# Where is your data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5596a280-d166-4de8-8c7b-854a87713f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = 'images/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755c3978-e308-438d-83f3-cc8e655cd6ab",
   "metadata": {},
   "source": [
    "# Set a few variables for the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7000467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make output directory for plots\n",
    "output_dir = 'output/'\n",
    "\n",
    "# save plots\n",
    "save_plots = True\n",
    "\n",
    "# show plots\n",
    "show_plots = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6a6c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all image paths in the given directory\n",
    "def gather_image_from_dir(input_dir):\n",
    "    image_extensions = ['*.bmp', '*.jpg', '*.png']\n",
    "    image_list = []\n",
    "    for image_extension in image_extensions:\n",
    "        image_list.extend(glob.glob(input_dir + image_extension))\n",
    "    image_list.sort()\n",
    "    return image_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2b90a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_image_to_screen(image, screen_width=1920, screen_height=1080, scale=0.75):\n",
    "    height, width = image.shape[:2]\n",
    "    width_scale = float(screen_width) / float(width)\n",
    "    height_scale = float(screen_height) / float(height)\n",
    "    # if image fits to desired screen size, do not resize\n",
    "    if width_scale > 1.0:\n",
    "        width_scale = 1.0\n",
    "    if height_scale > 1.0:\n",
    "        height_scale = 1.0\n",
    "    image_scale = height_scale if width_scale > height_scale else width_scale\n",
    "    image_scale *= scale\n",
    "    resized_image = cv2.resize(image, (0, 0), fx=image_scale, fy=image_scale)\n",
    "    return resized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2ce0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find annotation path according to the given name\n",
    "def find_file_by_name(name, paths):\n",
    "    for path in paths:\n",
    "        # Extract the filename without extension from the path\n",
    "        filename_without_extension = os.path.splitext(os.path.basename(path))[0]\n",
    "\n",
    "        # Check if the filename without extension matches the given filename without extension\n",
    "        if filename_without_extension == name:\n",
    "            return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864dd82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather images and labels\n",
    "image_paths = gather_image_from_dir(image_dir)\n",
    "print(f'Image count: {len(image_paths)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b058854",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_image(image):\n",
    "    transform = A.Compose([\n",
    "            A.OneOf\n",
    "            ([\n",
    "                A.HorizontalFlip(p=0.6),\n",
    "                A.ShiftScaleRotate(p=0.6,\n",
    "                                   scale_limit=(-0.05, 0.05),\n",
    "                                   shift_limit=(-0.05, 0.05),\n",
    "                                   rotate_limit=(-10, 10))\n",
    "            ]),\n",
    "            A.OneOf\n",
    "            ([\n",
    "                A.RandomBrightnessContrast(p=0.5,\n",
    "                                           brightness_limit=0.15,\n",
    "                                           contrast_limit=0.15),\n",
    "                A.RandomGamma(p=0.5,\n",
    "                              gamma_limit=(75, 125))\n",
    "            ]),\n",
    "            A.ISONoise(p=0.5,\n",
    "                       color_shift=(0.01, 0.1),\n",
    "                       intensity=(0.2, 0.5))\n",
    "            ])\n",
    "    transformed = transform(image=image)\n",
    "    return transformed[\"image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229c65a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_multiple_images(image_dict: dict, output_dir: str, image_name: str, save_files: bool = True):\n",
    "    \"\"\"\n",
    "    image_dict - image dictionary consisting of image name and image \n",
    "    \"\"\"\n",
    "    size = 25\n",
    "    fig, axes = plt.subplots(1, len(image_dict), figsize=(size * len(image_dict), size))\n",
    "    for index, (name, image) in enumerate(image_dict.items()):\n",
    "        if len(image.shape) == 2:\n",
    "            axes[index].imshow(image, cmap='gray')\n",
    "        else:\n",
    "            axes[index].imshow(image)\n",
    "        axes[index].set_title(name, fontsize=size*2)\n",
    "    for ax in axes:\n",
    "        ax.tick_params(axis='both', which='major', labelsize=size)  # Adjust the fontsize as needed\n",
    "    plt.tight_layout()\n",
    "    if save_files:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        output_path = output_dir + image_name + '.png'\n",
    "        plt.savefig(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320edb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_few_aumentations(image, augmentations_count=1):\n",
    "    \"\"\"\n",
    "    Return dictionary of original image + augmentations\n",
    "    \"\"\"\n",
    "    image_dict = {'Original': image}    \n",
    "    for index in range(augmentations_count):\n",
    "        augm_image = transform_image(image)\n",
    "        image_dict.update({f'Augmentation {index}': augm_image})\n",
    "    return image_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4c66fb-f330-46e6-9d49-376947eae2c4",
   "metadata": {},
   "source": [
    "# Make some image aumentation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0f9951-538a-40cb-831b-62a6654ea01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many augmentation do you want to do for the same image?\n",
    "augmentations_in_row_count = 2 # how many augmentations do you want to see in row\n",
    "augmentations_count = 3 # how time generate image row with augmentations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bb8cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, image_path in enumerate(image_paths):\n",
    "    image_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "    image_height, image_width = image.shape[:2]\n",
    "    # BGR (OpenCV original) to RGB\n",
    "    image_RGB = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    for augmentation_i in range(augmentations_count):   \n",
    "        # let's augment a few times to check how it will look\n",
    "        image_dict = make_few_aumentations(image_RGB, augmentations_count=augmentations_in_row_count)\n",
    "        plot_multiple_images(image_dict, output_dir, f'{image_name} [{augmentation_i}]', save_plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e30f493-ef3d-4115-93e4-17f27eba814c",
   "metadata": {},
   "source": [
    "## In the following links you can find Albumentations applications with Tensorflow and PyTorch training routines:\n",
    "1. Tensorflow image classification: https://github.com/rytisss/DL-defect-classification-with-CAM-output/blob/main/CAM%20classifiers.ipynb\n",
    "2. PyTorch image classification: https://albumentations.ai/docs/examples/pytorch_classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57290587-a8e9-435b-ae95-b95faf7151ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
